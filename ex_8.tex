%% LaTeX Beamer presentation template (requires beamer package)
%% see http://bitbucket.org/rivanvx/beamer/wiki/Home
%% idea contributed by H. Turgut Uyar
%% template based on a template by Till Tantau
%% this template is still evolving - it might differ in future releases!

%% Template edited by Panagiotis Adamopoulos {padamopo}@stern.nyu.edu

\documentclass[aspectratio=169]{beamer}
 
\mode<presentation>
{
\usetheme{NYU}

\setbeamercovered{transparent}
}

\usepackage[english]{babel}
\usepackage[latin1]{inputenc}
\usepackage[scaled=.90]{helvet}
\usepackage{courier}
\usepackage[T1]{fontenc}
\usepackage{comment}
%usepackage{appendixnumberbeamer}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{pgfpages}
% citations
\usepackage{natbib}
\bibpunct{(}{)}{;}{a}{,}{,}
\def\citeapos#1{\citeauthor{#1}'s (\citeyear{#1})}
\renewcommand{\bibsection}{\subsubsection*{\bibname } }
\input{latex-math/basic-math.tex}
\input{latex-math/basic-ml.tex}

\newcommand{\thetahi}{\thetah_i}
\newcommand{\thetai}{\theta_i}
\newcommand{\thetainnz}{\id_{|\theta_i| \neq 0}}
\newcommand{\Imat}{\mathbf{I}}
\newcommand{\sumip}{\sum_{i=1}^p}



\title[]{\textbf{Exercise of Supervised Learning: \\ Regularization Part 1}}

%\subtitle{}

% - Use the \inst{?} command only if the authors have different
%   affiliation.
%\author{F.~Author\inst{1} \and S.~Another\inst{2}}
\author{Yawei Li} 

% - Use the \inst command only if there are several affiliations.
% - Keep it simple, no one is interested in your street address.
\institute[LMU]
{
\\
  \texttt{yawei.li@stat.uni-muenchen.de}
}

\date{December 8, 2023}


% This is only inserted into the PDF information catalog. Can be left
% out.
\subject{Subject}



% If you have a file called "university-logo-filename.xxx", where xxx
% is a graphic format that can be processed by latex or pdflatex,
% resp., then you can add a logo as follows:

% \pgfdeclareimage[height=0.5cm]{university-logo}{university-logo-filename}
% \logo{\pgfuseimage{university-logo}}



% Delete this, if you do not want the table of contents to pop up at
% the beginning of each subsection:
%\AtBeginSubsection[]
%{
%\begin{frame}<beamer>
%\frametitle{Outline}
%\tableofcontents[currentsection,currentsubsection]
%\end{frame}
%}

% If you wish to uncover everything in a step-wise fashion, uncomment
% the following command:

%\beamerdefaultoverlayspecification{<+->}

\begin{document}



\begin{frame}[noframenumbering, plain]
\titlepage

\end{frame}



\begin{frame}{Exercise 1: L0 Regularization}
	\small
	Consider the regression learning setting, i.e., $\Yspace = \mathbb{R}$, and the feature space $\Xspace = \mathbb{R}^p$. Let the hypothesis space be the linear models: $$\Hspace = \{ \fx = \thetab^T \xv \ | \ \thetab \in \mathbb{R}^p \}.$$
	
	Suppose your loss function of interest is the L2 loss $L(y, \fx) = \frac{1}{2} (y - \fx)^2$. Consider the $L_0$-regularized empirical risk of a model $\fxt$: 
	
	$$
		\riskrt = \risket + \lambda ||\thetab ||_0 = \frac{1}{2} \sum_{i=1}^n (\yi - \thetab^T \xi )^2 + \lambda \sum_{i=1}^p \thetainnz.
	$$
	
	Assume that $\Xmat^T \Xmat = \Imat$, which holds if $\Xmat$ has orthonormal columns. Show that the minimizer $\thetah_{L0} = (\thetah_{L0, 1}, \ldots, \thetah_{L0, p})^T$ is given by 
	$$
		\thetah_{L0, i} = \thetahi \id_{\thetahi > \sqrt{2 \lambda}}, \qquad i = 1, \ldots, p,
	$$
	where $\thetabh = (\thetah_1, \ldots, \thetah_p)^T = (\Xmat^T \Xmat)^{-1} \Xmat^T \yv$ is the minimizer of the unregularized empirical risk. For this purpose, using the following steps:
	
\end{frame}

\begin{frame}{Exercise 1 (i)}
	(i) Derive that 
	\begin{align*}
		\argmin_{\thetab} \risket = \argmin_{\thetab} \sumip - \thetahi \thetai + \frac{\thetai^2}{2} + \lambda \thetainnz.
	\end{align*}
\end{frame}

\begin{frame}{Solution to Exercise 1 (i)}
	
\end{frame}

\end{document}
